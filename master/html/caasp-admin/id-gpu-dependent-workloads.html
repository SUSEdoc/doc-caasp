<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang=""><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>GPU-Dependent Workloads | Administration Guide | SUSE CaaS Platform 4.5.2</title><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" /><link rel="stylesheet" type="text/css" href="static/css/style.css" /><link rel="stylesheet" type="text/css" href="static/css/highlight.css" /><meta name="generator" content="DAPS 3.2.0 (https://opensuse.github.io/daps) using SUSE XSL Stylesheets 2.81.0 (based on DocBook XSL Stylesheets 1.79.2) - chunked" /><meta name="product-name" content="SUSE CaaS Platform" /><meta name="product-number" content="4.5.2" /><meta name="book-title" content="Administration Guide" /><meta name="chapter-title" content="Chapter 11. GPU-Dependent Workloads" /><meta name="description" content="This feature is offered as a tech preview ." /><meta name="tracker-url" content="https://github.com/SUSE/doc-caasp/issues/new" /><meta name="tracker-type" content="gh" /><meta name="tracker-gh-labels" content="AdminGuide" /><link rel="home" href="index.html" title="Administration Guide" /><link rel="up" href="index.html" title="Administration Guide" /><link rel="prev" href="id-integration.html" title="Chapter 10. Integration" /><link rel="next" href="id-cluster-disaster-recovery.html" title="Chapter 12. Cluster Disaster Recovery" />
<script type="text/javascript">

if ( window.location.protocol.toLowerCase() != 'file:' ) {
  document.write('<link rel="stylesheet" type="text/css" href="https://static.opensuse.org/fonts/fonts.css"></link>');
}
else {
  document.write('<link rel="stylesheet" type="text/css" href="static/css/fonts-onlylocal.css"></link>');
}

</script><noscript><link rel="stylesheet" type="text/css" href="https://static.opensuse.org/fonts/fonts.css" /></noscript><script src="static/js/jquery-1.10.2.min.js" type="text/javascript"></script><script src="static/js/script.js" type="text/javascript"></script><script src="static/js/highlight.min.js" type="text/javascript"></script><script>

$(document).ready(function() {
  $('.verbatim-wrap.highlight').each(function(i, block) {
    hljs.highlightBlock(block);
  });
});
hljs.configure({
  useBR: false
});

</script></head><body class="draft offline js-off" onload="$('#betawarn-button-wrap').toggle();if (document.cookie.length > 0) {if (document.cookie.indexOf('betawarn=closed') != -1){$('#betawarn').toggle()}};"><div id="betawarn" style="position:fixed;bottom:0;z-index:9025;background-color:#FDE8E8;padding:1em;margin-left:10%;margin-right:10%;display:block;border-top:.75em solid #E11;width:80%"><p style="color:#333;margin:1em 0;padding:0;">This is a draft document that was built and uploaded automatically. It may document beta software and be incomplete or even incorrect. <strong>Use this document at your own risk.</strong></p> <div id="betawarn-button-wrap" style="display:none;margin:0;padding:0;"><a href="#" onclick="$('#betawarn').toggle();var d=new Date();d.setTime(d.getTime()+(0.5*24*60*60*1000));document.cookie='betawarn=closed; expires='+d.toUTCString()+'; path=/'; return false;" style="color:#333;text-decoration:underline;float:left;margin-top:.5em;padding:1em;display:block;background-color:#FABEBE;">I understand this is a draft</a></div></div><div class="bypass-block"><a href="#_content">Jump to content</a><a href="#_bottom-navigation">Jump to page navigation: previous page [access key p]/next page [access key n]</a></div><div id="_outer-wrap"><div id="_white-bg" style="background-color: #E11;"><div id="_header"><div id="_logo"><img src="static/images/logo.png" alt="Logo" /></div><div class="crumbs"><a class="book-link" href="index.html" title="Administration Guide"><span class="book-icon">Administration Guide</span></a><span> › </span><a class="crumb" href="id-gpu-dependent-workloads.html">GPU-Dependent Workloads</a></div><div class="clearme"></div></div></div><div id="_toolbar-wrap"><div id="_toolbar"><div id="_toc-area" class="inactive"><a id="_toc-area-button" class="tool" title="Contents" accesskey="c" href="index.html"><span class="tool-spacer"><span class="toc-icon">Contents</span><span class="clearme"></span></span><span class="tool-label">Contents</span></a><div class="active-contents bubble-corner"></div><div class="active-contents bubble"><div class="bubble-container"><h6>Administration Guide</h6><div id="_bubble-toc"><ol><li class="inactive"><a href="pr01.html"><span class="number"> </span><span class="name"></span></a></li><li class="inactive"><a href="id-about-this-guide.html"><span class="number">1 </span><span class="name">About This Guide</span></a></li><li class="inactive"><a href="id-cluster-management.html"><span class="number">2 </span><span class="name">Cluster Management</span></a></li><li class="inactive"><a href="id-software-management.html"><span class="number">3 </span><span class="name">Software Management</span></a></li><li class="inactive"><a href="id-cluster-updates.html"><span class="number">4 </span><span class="name">Cluster Updates</span></a></li><li class="inactive"><a href="id-upgrading-suse-caas-platform.html"><span class="number">5 </span><span class="name">Upgrading SUSE CaaS Platform</span></a></li><li class="inactive"><a href="id-security.html"><span class="number">6 </span><span class="name">Security</span></a></li><li class="inactive"><a href="id-logging.html"><span class="number">7 </span><span class="name">Logging</span></a></li><li class="inactive"><a href="id-monitoring.html"><span class="number">8 </span><span class="name">Monitoring</span></a></li><li class="inactive"><a href="id-storage.html"><span class="number">9 </span><span class="name">Storage</span></a></li><li class="inactive"><a href="id-integration.html"><span class="number">10 </span><span class="name">Integration</span></a></li><li class="inactive"><a href="id-gpu-dependent-workloads.html"><span class="number">11 </span><span class="name">GPU-Dependent Workloads</span></a></li><li class="inactive"><a href="id-cluster-disaster-recovery.html"><span class="number">12 </span><span class="name">Cluster Disaster Recovery</span></a></li><li class="inactive"><a href="backup-and-restore-with-velero.html"><span class="number">13 </span><span class="name">Backup and Restore with Velero</span></a></li><li class="inactive"><a href="id-miscellaneous.html"><span class="number">14 </span><span class="name">Miscellaneous</span></a></li><li class="inactive"><a href="id-troubleshooting-3.html"><span class="number">15 </span><span class="name">Troubleshooting</span></a></li><li class="inactive"><a href="id-glossary.html"><span class="number">16 </span><span class="name">Glossary</span></a></li><li class="inactive"><a href="id-contributors.html"><span class="number">A </span><span class="name">Contributors</span></a></li><li class="inactive"><a href="id-gnu-licenses.html"><span class="number">B </span><span class="name">GNU Licenses</span></a></li></ol></div><div class="clearme"></div></div></div></div><div id="_nav-area" class="inactive"><div class="tool"><span class="nav-inner"><span class="tool-label">Navigation</span><a accesskey="p" class="tool-spacer" title="Chapter 10. Integration" href="id-integration.html"><span class="prev-icon">←</span></a><a accesskey="n" class="tool-spacer" title="Chapter 12. Cluster Disaster Recovery" href="id-cluster-disaster-recovery.html"><span class="next-icon">→</span></a></span></div></div></div></div><div id="_fixed-header-wrap" style="background-color: #E11;" class="inactive"><div id="_fixed-header"><div class="crumbs"><a class="book-link" href="index.html" title="Administration Guide"><span class="book-icon">Administration Guide</span></a><span> › </span><a class="crumb" href="id-gpu-dependent-workloads.html">GPU-Dependent Workloads</a></div><div class="buttons"><a class="top-button button" href="#">Top</a><div class="button"><a accesskey="p" class="tool-spacer" title="Chapter 10. Integration" href="id-integration.html"><span class="prev-icon">←</span></a><a accesskey="n" class="tool-spacer" title="Chapter 12. Cluster Disaster Recovery" href="id-cluster-disaster-recovery.html"><span class="next-icon">→</span></a></div><div class="clearme"></div></div><div class="clearme"></div></div></div><div id="_content" class="draft "><div class="documentation"><div class="chapter " id="id-gpu-dependent-workloads"><div class="titlepage"><div><div class="version-info">Applies to  <span class="productname ">SUSE CaaS Platform</span> <span class="productnumber ">4.5.2</span></div><div><h1 class="title"><span class="number">11 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">GPU-Dependent Workloads</span> <a title="Permalink" class="permalink" href="id-gpu-dependent-workloads.html#">#</a></h1></div></div></div><div class="line"><div class="toc"><dl><dt><span class="section"><a href="id-gpu-dependent-workloads.html#gpus"><span class="number">11.1 </span><span class="name">NVIDIA GPUs</span></a></span></dt></dl></div></div><div class="sect1" id="gpus"><div class="titlepage"><div><div><h2 class="title"><span class="number">11.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">NVIDIA GPUs</span> <a title="Permalink" class="permalink" href="id-gpu-dependent-workloads.html#gpus">#</a></h2></div></div></div><div id="id-1.13.2.2" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>This feature is offered as a "tech preview".</p><p>We release this as a tech-preview in order to get early feedback from our customers.
Tech previews are largely untested, unsupported, and thus not ready for production use.</p><p>That said, we strongly believe this technology is useful at this stage in order to make the right improvements based on your feedback.
A fully supported, production-ready release is planned for a later point in time.</p></div><p>Graphics Processing Units (GPUs) provide a powerful way to run compute-intensive workloads such as machine learning pipelines. SUSE’s CaaS Platform supports scheduling GPU-dependent workloads on NVIDIA GPUs as a technical preview. This section illustrates how to prepare your host machine to expose GPU devices to your containers, and how to configure Kubernetes to schedule GPU-dependent workloads.</p><div class="sect2" id="id-prepare-the-host-machine"><div class="titlepage"><div><div><h3 class="title"><span class="number">11.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Prepare the host machine</span> <a title="Permalink" class="permalink" href="id-gpu-dependent-workloads.html#id-prepare-the-host-machine">#</a></h3></div></div></div><div class="sect3" id="id-install-the-gpu-drivers"><div class="titlepage"><div><div><h4 class="title"><span class="number">11.1.1.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Install the GPU drivers</span> <a title="Permalink" class="permalink" href="id-gpu-dependent-workloads.html#id-install-the-gpu-drivers">#</a></h4></div></div></div><p>Not every worker node in the cluster need have a GPU device present. On the nodes that do have one or more NVIDIA GPUs, install the drivers from NVIDIA’s repository.</p><div class="verbatim-wrap highlight bash"><pre class="screen"># zypper addrepo --refresh https://download.nvidia.com/suse/sle15sp2/ nvidia
# zypper refresh
# zypper install nvidia-glG05 nvidia-computeG05</pre></div><div id="id-1.13.2.4.2.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>For most modern NVIDIA GPUs, the G05 driver will support your device.
Check NVIDIA’s documentation for your GPU device model.</p></div></div><div class="sect3" id="id-install-the-oci-hooks"><div class="titlepage"><div><div><h4 class="title"><span class="number">11.1.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Install the OCI hooks</span> <a title="Permalink" class="permalink" href="id-gpu-dependent-workloads.html#id-install-the-oci-hooks">#</a></h4></div></div></div><p>OCI hooks are a way for vendors or projects to inject executable actions into the lifecycle of a container managed by the container runtime (runc). SUSE provides an OCI hook for NVIDIA that enable the container runtime and therefor the kubelet and the Kubernetes scheduler to query the host system for the presence of a GPU device and access it directly. Install the hook on the worker nodes with GPUs:</p><div class="verbatim-wrap highlight bash"><pre class="screen"># zypper install nvidia-container-toolkit</pre></div></div><div class="sect3" id="id-test-a-gpu-container-image"><div class="titlepage"><div><div><h4 class="title"><span class="number">11.1.1.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Test a GPU Container Image</span> <a title="Permalink" class="permalink" href="id-gpu-dependent-workloads.html#id-test-a-gpu-container-image">#</a></h4></div></div></div><p>At this point, you should be able to run a container image that requires a GPU and directly access the device from the running container, for example using Podman:</p><div class="verbatim-wrap highlight bash"><pre class="screen"># podman run docker.io/nvidia/cuda nvidia-smi</pre></div></div><div class="sect3" id="id-troubleshooting"><div class="titlepage"><div><div><h4 class="title"><span class="number">11.1.1.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Troubleshooting</span> <a title="Permalink" class="permalink" href="id-gpu-dependent-workloads.html#id-troubleshooting">#</a></h4></div></div></div><p>At this point, you should be able to run a container image using a GPU. If that is not working, check the following:</p><p>Ensure your GPU is visible from the host system:</p><div class="verbatim-wrap highlight bash"><pre class="screen"># lspci | grep -i nvidia
# nvidia-smi</pre></div><p>Ensure the kernel modules are loaded:</p><div class="verbatim-wrap highlight bash"><pre class="screen"># lsmod | grep nvidia</pre></div><p>If they are not, try loading them explicitly and check dmesg for an error indicating why they are missing:</p><div class="verbatim-wrap highlight bash"><pre class="screen"># nvidia-modprobe
# dmesg | tail</pre></div></div></div><div class="sect2" id="id-configure-kubernetes"><div class="titlepage"><div><div><h3 class="title"><span class="number">11.1.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure Kubernetes</span> <a title="Permalink" class="permalink" href="id-gpu-dependent-workloads.html#id-configure-kubernetes">#</a></h3></div></div></div><div class="sect3" id="id-install-the-device-plugin"><div class="titlepage"><div><div><h4 class="title"><span class="number">11.1.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Install the Device Plugin</span> <a title="Permalink" class="permalink" href="id-gpu-dependent-workloads.html#id-install-the-device-plugin">#</a></h4></div></div></div><p>The Kubernetes device plugin framework allows the kubelet to advertise system hardware resources that the Kubernetes scheduler can then use as hints to schedule workloads that require such devices. The Kubernetesdevice plugin from NVIDIA allows the kubelet to advertise NVIDIA GPUs it finds present on the worker node. Install the device plugin using kubectl:</p><div class="verbatim-wrap highlight bash"><pre class="screen">$ kubectl create -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/1.0.0-beta6/nvidia-device-plugin.yml</pre></div></div><div class="sect3" id="id-taint-gpu-workers"><div class="titlepage"><div><div><h4 class="title"><span class="number">11.1.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Taint GPU Workers</span> <a title="Permalink" class="permalink" href="id-gpu-dependent-workloads.html#id-taint-gpu-workers">#</a></h4></div></div></div><p>In a heterogeneous cluster, it may be preferable to prevent scheduling pods that do not require a GPU on nodes with a GPU in order to ensure that GPU workloads are not competing for time on the hardware they need to run. To accomplish this, add a taint to the worker nodes that have GPUs:</p><div class="verbatim-wrap highlight bash"><pre class="screen">$ kubectl taint nodes worker0 nvidia.com/gpu=:PreferNoSchedule</pre></div><p>or</p><div class="verbatim-wrap highlight bash"><pre class="screen">$ kubectl taint nodes worker0 nvidia.com/gpu=:NoSchedule</pre></div><p>See the Kubernetes documentation on <a class="link" href="https://v1-18.docs.kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/" target="_blank">taints and tolerations</a> for a discussion on the considerations for using the NoSchedule or PreferNoSchedule effects. If you use the NoSchedule effect, you must also add the appropriate toleration to infrastructure-critical Daemonsets that must run on all nodes, such as the kured, kube-proxy, and cilium Daemonsets.</p><div id="id-1.13.2.5.3.7" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>The <a class="link" href="https://v1-18.docs.kubernetes.io/docs/reference/access-authn-authz/admission-controllers/#extendedresourcetoleration" target="_blank">ExtendedResourceToleration admission controller</a> is enabled on SUSE CaaS Platform v5 by default. This is a mutating admission controller that reviews all pod requests and adds tolerations to any pod that requests an extended resource advertised by a device plugin. For the NVIDIA GPU device plugin, it will automatically add the nvidia.com/gpu toleration to pods that request the nvidia.com/gpu resource, so you will not need to add this toleration explicitly for every GPU workload.</p></div></div><div class="sect3" id="id-test-a-gpu-workload"><div class="titlepage"><div><div><h4 class="title"><span class="number">11.1.2.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Test a GPU Workload</span> <a title="Permalink" class="permalink" href="id-gpu-dependent-workloads.html#id-test-a-gpu-workload">#</a></h4></div></div></div><p>To test your installation you can create a pod that requests GPU devices:</p><div class="verbatim-wrap highlight bash"><pre class="screen">$ kubectl apply -f - &lt;&lt;EOF
apiVersion: v1
kind: Pod
metadata:
  name: gpu-pod
spec:
  containers:
    - name: cuda-container
      image: nvidia/cuda:9.0-devel
      resources:
        limits:
          nvidia.com/gpu: 1 # requesting 1 GPU
    - name: digits-container
      image: nvidia/digits:6.0
      resources:
        limits:
          nvidia.com/gpu: 1 # requesting 1 GPU
EOF</pre></div><p>This example requests a total of two GPUs for two containers. If two GPUs are available on a worker in your cluster, this pod will be scheduled to that worker.</p></div><div class="sect3" id="id-troubleshooting-2"><div class="titlepage"><div><div><h4 class="title"><span class="number">11.1.2.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Troubleshooting</span> <a title="Permalink" class="permalink" href="id-gpu-dependent-workloads.html#id-troubleshooting-2">#</a></h4></div></div></div><p>At this point, after a few moments your pod should transition to state "running". If it is not, check the following:</p><p>Examine the pod events for an indication of why it is not being scheduled:</p><div class="verbatim-wrap highlight bash"><pre class="screen">$ kubectl describe pod gpu-pod</pre></div><p>Examine the events for the device plugin daemonset for any issues:</p><div class="verbatim-wrap highlight bash"><pre class="screen">$ kubectl describe daemonset nvidia-device-plugin-daemonset --namespace kube-system</pre></div><p>Check the logs of each pod in the daemonset running on a worker that has a GPU:</p><div class="verbatim-wrap highlight bash"><pre class="screen">$ kubectl logs -l name=nvidia-device-plugin-ds --namespace kube-system</pre></div><p>Check the kubelet log on the worker node that has a GPU. This may indicate errors the container runtime had executing the OCI hook command:</p><div class="verbatim-wrap highlight bash"><pre class="screen"># journalctl -u kubelet</pre></div></div></div><div class="sect2" id="id-monitoring-3"><div class="titlepage"><div><div><h3 class="title"><span class="number">11.1.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Monitoring</span> <a title="Permalink" class="permalink" href="id-gpu-dependent-workloads.html#id-monitoring-3">#</a></h3></div></div></div><p>If you have configured <a class="link" href="https://documentation.suse.com/suse-caasp/4.5//html/caasp-admin/_monitoring.html" target="_blank">Monitoring</a> for your cluster, you may want to use NVIDIA’s <a class="link" href="https://developer.nvidia.com/dcgm" target="_blank">Data Center GPU Manager (DCGM) to monitor your GPUs</a>. DCGM integrates with the Prometheus and Grafana services configured for your cluster. Follow the steps below to configure the Prometheus exporter and Grafana dashboard for your NVIDIA GPUs.</p><div class="sect3" id="id-configure-a-pod-security-policy"><div class="titlepage"><div><div><h4 class="title"><span class="number">11.1.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure a Pod Security Policy</span> <a title="Permalink" class="permalink" href="id-gpu-dependent-workloads.html#id-configure-a-pod-security-policy">#</a></h4></div></div></div><p>The DCGM requires use of the hostPath volume type to access the kubelet socket on the host worker node. Create an appropriate Pod Security Policy and RBAC configuration to allow this:</p><div class="verbatim-wrap highlight bash"><pre class="screen">$ kubectl apply -f - &lt;&lt;EOF
---
apiVersion: policy/v1beta1
kind: PodSecurityPolicy
metadata:
  name: nvidia.dcgm
spec:
  privileged: false
  seLinux:
    rule: RunAsAny
  supplementalGroups:
    rule: RunAsAny
  runAsUser:
    rule: RunAsAny
  fsGroup:
    rule: RunAsAny
  allowedHostPaths:
    - pathPrefix: /var/lib/kubelet/pod-resources
  volumes:
  - hostPath
  - configMap
  - secret
  - emptyDir
  - downwardAPI
  - projected
  - persistentVolumeClaim
  - nfs
  - rbd
  - cephFS
  - glusterfs
  - fc
  - iscsi
  - cinder
  - gcePersistentDisk
  - awsElasticBlockStore
  - azureDisk
  - azureFile
  - vsphereVolume
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: nvidia:dcgm
rules:
- apiGroups:
  - policy
  resources:
  - podsecuritypolicies
  verbs:
  - use
  resourceNames:
  - nvidia.dcgm
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: nvidia:dcgm
roleRef:
  kind: ClusterRole
  name: nvidia:dcgm
  apiGroup: rbac.authorization.k8s.io
subjects:
- kind: Group
  name: system:serviceaccounts:dcgm
EOF</pre></div></div><div class="sect3" id="id-create-the-dcgm-exporter"><div class="titlepage"><div><div><h4 class="title"><span class="number">11.1.3.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Create the DCGM Exporter</span> <a title="Permalink" class="permalink" href="id-gpu-dependent-workloads.html#id-create-the-dcgm-exporter">#</a></h4></div></div></div><p>The DCGM exporter monitors GPUs on each worker node and exposes metrics that can be queried.</p><div class="verbatim-wrap highlight bash"><pre class="screen">$ kubectl create namespace dcgm
$ kubectl create --namespace dcgm -f https://raw.githubusercontent.com/NVIDIA/gpu-monitoring-tools/master/dcgm-exporter.yaml</pre></div><p>Check that the metrics are being collected:</p><div class="verbatim-wrap highlight bash"><pre class="screen">$ NAME=$(kubectl get pods --namespace dcgm -l "app.kubernetes.io/name=dcgm-exporter" -o "jsonpath={ .items[0].metadata.name}")
$ kubectl port-forward $NAME 8080:9400
$ # in another terminal
$ curl http://127.0.0.1:8080/metrics</pre></div></div><div class="sect3" id="id-configure-prometheus"><div class="titlepage"><div><div><h4 class="title"><span class="number">11.1.3.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Configure Prometheus</span> <a title="Permalink" class="permalink" href="id-gpu-dependent-workloads.html#id-configure-prometheus">#</a></h4></div></div></div><p>After deploying Prometheus as explained in <a class="link" href="https://documentation.suse.com/suse-caasp/4.5//html/caasp-admin/_monitoring.html" target="_blank">Monitoring</a>, configure Prometheus to monitor the DCGM pods. Gather the cluster IPs of the pods to monitor:</p><div class="verbatim-wrap highlight bash"><pre class="screen">$ kubectl get pods --namespace dcgm -l "app.kubernetes.io/name=dcgm-exporter" -o "jsonpath={ .items[*].status.podIP}"
10.244.1.10 10.244.2.68</pre></div><p>Add the DCGM pods to Prometheus’s scrape configuration. Edit the Prometheus configmap:</p><div class="verbatim-wrap highlight bash"><pre class="screen">$ kubectl edit --namespace monitoring configmap prometheus-server</pre></div><p>Under the <code class="literal">scrape_configs</code> section add a new job, using the pod IPs found above:</p><div class="verbatim-wrap highlight yaml"><pre class="screen">scrape_configs:
...
- job_name: dcgm
  static_configs:
  - targets: ['10.244.1.10:9400', '10.244.2.68:9400']
...</pre></div><p>Prometheus will automatically reload the new configuration.</p></div><div class="sect3" id="id-add-the-grafana-dashboard"><div class="titlepage"><div><div><h4 class="title"><span class="number">11.1.3.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Add the Grafana Dashboard</span> <a title="Permalink" class="permalink" href="id-gpu-dependent-workloads.html#id-add-the-grafana-dashboard">#</a></h4></div></div></div><p>Import the DCGM Exporter dashboard into Grafana.</p><p>In the Grafana web interface, navigate to <span class="guimenu ">Manage Dashboards</span> › <span class="guimenu ">Import</span>. In the field <span class="emphasis"><em>_Import via grafana.com</em></span>, enter the dashboard ID <code class="literal">12219</code>, and click <span class="guimenu ">Load</span>.</p><p>Alternatively, download the <a class="link" href="https://raw.githubusercontent.com/NVIDIA/gpu-monitoring-tools/2.0.0-rc.11/grafana/dcgm-exporter-dashboard.json" target="_blank">dashboard JSON definition</a>, and upload it with the <span class="guimenu ">Upload .json file</span> button.</p><p>On the next page, in the dropdown menu <span class="guimenu ">Prometheus</span> › <span class="guimenu ">]</span> › <span class="guimenu ">select <span class="emphasis"><em>Prometheus</em></span> as the data source. Customize the dashboard name and UID to your preference. Then click menu:Import[</span>.</p><p>The new dashboard will appear in the Grafana web interface.</p></div></div></div></div></div><div class="page-bottom"><div id="_bottom-navigation"><a class="nav-link" href="id-cluster-disaster-recovery.html"><span class="next-icon">→</span><span class="nav-label"><span class="number">Chapter 12 </span>Cluster Disaster Recovery</span></a><a class="nav-link" href="id-integration.html"><span class="prev-icon">←</span><span class="nav-label"><span class="number">Chapter 10 </span>Integration</span></a></div><div class="_share-print"><div class="online-contents share"><strong>Share this page: </strong><span class="share-buttons"><span class="_share-fb bottom-button">Facebook</span><span class="spacer"> • </span><span class="_share-in bottom-button">LinkedIn</span><span class="spacer"> • </span><span class="_share-tw bottom-button">Twitter</span><span class="spacer"> • </span><span class="_share-mail bottom-button">E-Mail</span></span></div><div class="print"><span class="_print-button bottom-button">Print this page</span></div><div class="clearme"></div></div></div></div><div id="_inward"></div></div><div id="_footer-wrap"><div id="_footer"><p>©
        2021 
        SUSE</p><ul><li><a href="https://jobs.suse.com/" target="_top">Careers</a></li><li><a href="https://www.suse.com/company/legal/" target="_top">Legal</a></li><li><a href="https://www.suse.com/company/about/" target="_top">About</a></li><li><a href="https://www.suse.com/contact/" target="_top">Contact Us</a></li></ul></div></div></body></html>