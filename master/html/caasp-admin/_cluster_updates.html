<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang=""><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Cluster Updates | Administration Guide | SUSE CaaS Platform 4.5.2</title><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" /><link rel="stylesheet" type="text/css" href="static/css/style.css" /><link rel="stylesheet" type="text/css" href="static/css/highlight.css" /><meta name="generator" content="DAPS 3.0.0 (https://opensuse.github.io/daps) using SUSE XSL Stylesheets 2.0.17 (based on DocBook XSL Stylesheets 1.79.2) - chunked" /><meta name="product-name" content="SUSE CaaS Platform" /><meta name="product-number" content="4.5.2" /><meta name="book-title" content="Administration Guide" /><meta name="chapter-title" content="Chapter 4. Cluster Updates" /><meta name="description" content="Attempting a cluster update without updating the installed packages pattern on the management node, can lead to an incomplete or failed update." /><meta name="tracker-url" content="https://github.com/SUSE/doc-caasp/issues/new" /><meta name="tracker-type" content="gh" /><meta name="tracker-gh-labels" content="AdminGuide" /><link rel="home" href="index.html" title="Administration Guide" /><link rel="up" href="index.html" title="Administration Guide" /><link rel="prev" href="_software_management.html" title="Chapter 3. Software Management" /><link rel="next" href="_upgrading_suse_caas_platform.html" title="Chapter 5. Upgrading SUSE CaaS Platform" />
<script type="text/javascript">

if ( window.location.protocol.toLowerCase() != 'file:' ) {
  document.write('<link rel="stylesheet" type="text/css" href="https://static.opensuse.org/fonts/fonts.css"></link>');
}
else {
  document.write('<link rel="stylesheet" type="text/css" href="static/css/fonts-onlylocal.css"></link>');
}

</script><noscript><link rel="stylesheet" type="text/css" href="https://static.opensuse.org/fonts/fonts.css" /></noscript><script src="static/js/jquery-1.10.2.min.js" type="text/javascript"></script><script src="static/js/script.js" type="text/javascript"></script><script src="static/js/highlight.min.js" type="text/javascript"></script><script>

$(document).ready(function() {
  $('.verbatim-wrap.highlight').each(function(i, block) {
    hljs.highlightBlock(block);
  });
});
hljs.configure({
  useBR: false
});

</script></head><body class="draft offline js-off" onload="$('#betawarn-button-wrap').toggle();if (document.cookie.length > 0) {if (document.cookie.indexOf('betawarn=closed') != -1){$('#betawarn').toggle()}};"><div id="betawarn" style="position:fixed;bottom:0;z-index:9025;background-color:#FDE8E8;padding:1em;margin-left:10%;margin-right:10%;display:block;border-top:.75em solid #E11;width:80%"><p style="color:#333;margin:1em 0;padding:0;">This is a draft document that was built and uploaded automatically. It may document beta software and be incomplete or even incorrect. <strong>Use this document at your own risk.</strong></p> <div id="betawarn-button-wrap" style="display:none;margin:0;padding:0;"><a href="#" onclick="$('#betawarn').toggle();var d=new Date();d.setTime(d.getTime()+(0.5*24*60*60*1000));document.cookie='betawarn=closed; expires='+d.toUTCString()+'; path=/'; return false;" style="color:#333;text-decoration:underline;float:left;margin-top:.5em;padding:1em;display:block;background-color:#FABEBE;">I understand this is a draft</a></div></div><div class="bypass-block"><a href="#_content">Jump to content</a><a href="#_bottom-navigation">Jump to page navigation: previous page [access key p]/next page [access key n]</a></div><div id="_outer-wrap"><div id="_white-bg" style="background-color: #FABEBE;"><div id="_header"><div id="_logo"><img src="static/images/logo.png" alt="Logo" /></div><div class="crumbs"><a class="book-link" href="index.html" title="Administration Guide"><span class="book-icon">Administration Guide</span></a><span> › </span><a class="crumb" href="_cluster_updates.html">Cluster Updates</a></div><div class="clearme"></div></div></div><div id="_toolbar-wrap"><div id="_toolbar"><div id="_toc-area" class="inactive"><a id="_toc-area-button" class="tool" title="Contents" accesskey="c" href="index.html"><span class="tool-spacer"><span class="toc-icon">Contents</span><span class="clearme"></span></span><span class="tool-label">Contents</span></a><div class="active-contents bubble-corner"></div><div class="active-contents bubble"><div class="bubble-container"><h6>Administration Guide</h6><div id="_bubble-toc"><ol><li class="inactive"><a href="pr01.html"><span class="number"> </span><span class="name"></span></a></li><li class="inactive"><a href="_about_this_guide.html"><span class="number">1 </span><span class="name">About This Guide</span></a></li><li class="inactive"><a href="_cluster_management.html"><span class="number">2 </span><span class="name">Cluster Management</span></a></li><li class="inactive"><a href="_software_management.html"><span class="number">3 </span><span class="name">Software Management</span></a></li><li class="inactive"><a href="_cluster_updates.html"><span class="number">4 </span><span class="name">Cluster Updates</span></a></li><li class="inactive"><a href="_upgrading_suse_caas_platform.html"><span class="number">5 </span><span class="name">Upgrading SUSE CaaS Platform</span></a></li><li class="inactive"><a href="_security.html"><span class="number">6 </span><span class="name">Security</span></a></li><li class="inactive"><a href="_logging.html"><span class="number">7 </span><span class="name">Logging</span></a></li><li class="inactive"><a href="_monitoring.html"><span class="number">8 </span><span class="name">Monitoring</span></a></li><li class="inactive"><a href="_storage.html"><span class="number">9 </span><span class="name">Storage</span></a></li><li class="inactive"><a href="_integration.html"><span class="number">10 </span><span class="name">Integration</span></a></li><li class="inactive"><a href="_gpu_dependent_workloads.html"><span class="number">11 </span><span class="name">GPU-Dependent Workloads</span></a></li><li class="inactive"><a href="_cluster_disaster_recovery.html"><span class="number">12 </span><span class="name">Cluster Disaster Recovery</span></a></li><li class="inactive"><a href="backup-and-restore-with-velero.html"><span class="number">13 </span><span class="name">Backup and Restore with Velero</span></a></li><li class="inactive"><a href="_miscellaneous.html"><span class="number">14 </span><span class="name">Miscellaneous</span></a></li><li class="inactive"><a href="_troubleshooting_3.html"><span class="number">15 </span><span class="name">Troubleshooting</span></a></li><li class="inactive"><a href="_glossary.html"><span class="number">16 </span><span class="name">Glossary</span></a></li><li class="inactive"><a href="_contributors.html"><span class="number">A </span><span class="name">Contributors</span></a></li><li class="inactive"><a href="_gnu_licenses.html"><span class="number">B </span><span class="name">GNU Licenses</span></a></li></ol></div><div class="clearme"></div></div></div></div><div id="_nav-area" class="inactive"><div class="tool"><span class="nav-inner"><span class="tool-label">Navigation</span><a accesskey="p" class="tool-spacer" title="Chapter 3. Software Management" href="_software_management.html"><span class="prev-icon">←</span></a><a accesskey="n" class="tool-spacer" title="Chapter 5. Upgrading SUSE CaaS Platform" href="_upgrading_suse_caas_platform.html"><span class="next-icon">→</span></a></span></div></div></div></div><div id="_fixed-header-wrap" style="background-color: #FABEBE;" class="inactive"><div id="_fixed-header"><div class="crumbs"><a class="book-link" href="index.html" title="Administration Guide"><span class="book-icon">Administration Guide</span></a><span> › </span><a class="crumb" href="_cluster_updates.html">Cluster Updates</a></div><div class="buttons"><a class="top-button button" href="#">Top</a><div class="button"><a accesskey="p" class="tool-spacer" title="Chapter 3. Software Management" href="_software_management.html"><span class="prev-icon">←</span></a><a accesskey="n" class="tool-spacer" title="Chapter 5. Upgrading SUSE CaaS Platform" href="_upgrading_suse_caas_platform.html"><span class="next-icon">→</span></a></div><div class="clearme"></div></div><div class="clearme"></div></div></div><div id="_content" class="draft "><div class="documentation"><div class="chapter " id="_cluster_updates"><div class="titlepage"><div><div class="version-info">Applies to  <span class="productname ">SUSE CaaS Platform</span> <span class="productnumber ">4.5.2</span></div><div><h1 class="title"><span class="number">4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Cluster Updates</span> <a title="Permalink" class="permalink" href="_cluster_updates.html#">#</a></h1></div></div></div><div class="line"><div class="toc"><dl><dt><span class="section"><a href="_cluster_updates.html#handling-updates"><span class="number">4.1 </span><span class="name">Update Requirements</span></a></span></dt><dt><span class="section"><a href="_cluster_updates.html#_updating_kubernetes_components"><span class="number">4.2 </span><span class="name">Updating Kubernetes Components</span></a></span></dt><dt><span class="section"><a href="_cluster_updates.html#_updating_nodes"><span class="number">4.3 </span><span class="name">Updating Nodes</span></a></span></dt><dt><span class="section"><a href="_cluster_updates.html#base-os-updates"><span class="number">4.4 </span><span class="name">Base OS Updates</span></a></span></dt></dl></div></div><div class="sect1" id="handling-updates"><div class="titlepage"><div><div><h2 class="title"><span class="number">4.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Update Requirements</span> <a title="Permalink" class="permalink" href="_cluster_updates.html#handling-updates">#</a></h2></div></div></div><div id="id-1.6.2.2" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>Attempting a cluster update without updating the installed packages pattern on the management node, can lead to an incomplete or failed update.</p></div><p>Before updating a SUSE CaaS Platform cluster, it’s required to update packages installed by the <code class="literal">SUSE-CaaSP-Management</code> pattern on the management workstation.</p><p>The cluster update depends on updated skuba, but might also require new helm / Terraform or other dependencies which will be updated with the refreshed pattern.</p><p>Run <code class="literal">sudo zypper update</code> on the management workstation before any attempt to update the cluster.</p></div><div class="sect1" id="_updating_kubernetes_components"><div class="titlepage"><div><div><h2 class="title"><span class="number">4.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Updating Kubernetes Components</span> <a title="Permalink" class="permalink" href="_cluster_updates.html#_updating_kubernetes_components">#</a></h2></div></div></div><p>Updating of Kubernetes and its components from one minor version to the next (for example from 1.16 to 1.17) is handled by <code class="literal">skuba</code>.
The reason for this is that <span class="strong"><strong>minor updates</strong></span> require special plan and apply procedures.
These procedures differ for <span class="strong"><strong>patch updates</strong></span> (for example 1.16.1 to 1.16.2), which are handled by <code class="literal">skuba-update</code> as described in <a class="xref" href="_cluster_updates.html#base-os-updates" title="4.4. Base OS Updates">Section 4.4, “Base OS Updates”</a>.</p><div id="id-1.6.3.3" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>Generally speaking: If you have other deployments not installed via Kubernetes or helm, update them last in the upgrade process.</p><p>However, if your applications/deployments in their current versions are incompatible with the Kubernetes version that you are upgrading to,
you must update these applications/deployments to a compatible version before attempting a cluster upgrade.</p><p>Refer to the individual application/deployment for the requirements for Kubernetes version and dependencies.</p></div><p>The general procedure should look like this:</p><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><p>Check if all current versions of applications and deployments in the cluster will work on the new Kubernetes version you plan to install.</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>If an application/deployment is incompatible with the new Kubernetes version, update the application/deployment before performing any of the other upgrade steps.</p></li></ul></div></li><li class="listitem "><p>Update the packages and reboot your management workstation to get all the latest changes to skuba, helm and their dependencies.</p></li><li class="listitem "><p>Run the commands on the management workstation.</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p><code class="literal">skuba addon refresh localconfig</code></p></li><li class="listitem "><p><code class="literal">skuba addon upgrade plan</code></p></li><li class="listitem "><p><code class="literal">skuba addon upgrade apply</code></p></li></ul></div></li><li class="listitem "><p>Apply all the configuration files that you modified for addons, the upgrade will have reset the configurations to defaults.</p></li><li class="listitem "><p>Check if there are addon upgrades available for the current cluster using <code class="literal">skuba addon upgrade plan</code>.</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Check if all the deployments in the cluster are compatible with the Kubernetes release that will be installed (refer to your individual deployments' documentation).</p></li><li class="listitem "><p>Check if the kustomize patches manifest is compatible for the current cluster, it will do Kubernetes server-side dry-run validation and displays the error message if present.
If the deployment is not compatible you must update it to ensure it working with the updated Kubernetes.</p></li></ul></div></li><li class="listitem "><p>Upgrade all master nodes by sequentially running <code class="literal">skuba node upgrade plan</code> and <code class="literal">skuba node upgrade apply</code>.</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Make sure to wait until all PODs/deployments/DaemonSets are up and running as expected before moving to the next node.</p></li></ul></div></li><li class="listitem "><p>Upgrade all worker nodes by sequentially running <code class="literal">skuba node upgrade plan</code> and <code class="literal">skuba node upgrade apply</code>.</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Make sure to wait until all PODs/deployments/DaemonSets are up and running as expected before moving to the next node.</p></li></ul></div></li><li class="listitem "><p>Check if new addons are available for the new version using <code class="literal">skuba addon upgrade plan</code> and do Kubernetes server-side dry-run validation to validates the addon base and patches manifest.</p></li><li class="listitem "><p>Once all nodes are up to date, update helm and subsequently the helm deployments.</p></li></ol></div><div class="sect2" id="_update_management_workstation"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.2.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Update Management Workstation</span> <a title="Permalink" class="permalink" href="_cluster_updates.html#_update_management_workstation">#</a></h3></div></div></div><p>Run <code class="literal">sudo zypper up</code> on your management workstation to get the latest version of <code class="literal">skuba</code> and its dependencies.
Reboot the machine to make sure that all system changes are correctly applied.</p></div><div class="sect2" id="_generating_an_overview_of_available_platform_updates"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.2.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Generating an Overview of Available Platform Updates</span> <a title="Permalink" class="permalink" href="_cluster_updates.html#_generating_an_overview_of_available_platform_updates">#</a></h3></div></div></div><p>To get an overview of the addon updates available with validating the addon base and patches manifest before being applied to the current cluster, you can run:</p><div class="verbatim-wrap"><pre class="screen">skuba cluster upgrade plan</pre></div><p>This will show you a list of updates (if available) for different components
installed on the cluster. If the cluster is already running the latest available
versions, the output should look like this:</p><div class="verbatim-wrap"><pre class="screen">Current Kubernetes cluster version: 1.16.2
Latest Kubernetes version: 1.16.2

Congratulations! You are already at the latest version available</pre></div><p>If the cluster has a new patch-level or minor Kubernetes version available, the
output should look like this:</p><div class="verbatim-wrap"><pre class="screen">Current Kubernetes cluster version: 1.15.2
Latest Kubernetes version: 1.16.2

Upgrade path to update from 1.15.2 to 1.16.2:
 - 1.15.2 -&gt; 1.16.2</pre></div><p>Similarly, you can also fetch this information on a per-node basis with the following command:</p><div class="verbatim-wrap"><pre class="screen">skuba node upgrade plan &lt;NODE&gt;</pre></div><p>For example, if the cluster has a node named <code class="literal">worker0</code> which is running the latest available versions, the output should look like this:</p><div class="verbatim-wrap"><pre class="screen">Current Kubernetes cluster version: 1.16.2
Latest Kubernetes version: 1.16.2

Node worker0 is up to date</pre></div><p>On the other hand, if this same node has a new patch-level or minor Kubernetes version available, the output should look like this:</p><div class="verbatim-wrap"><pre class="screen">Current Kubernetes cluster version: 1.15.2
Latest Kubernetes version: 1.16.2

Current Node version: 1.15.2

Component versions in worker0
  - kubelet: 1.15.2 -&gt; 1.16.2
  - cri-o: 1.15.0 -&gt; 1.16.0</pre></div><p>You will get a similar output if there is a version available on a master node
(named <code class="literal">master0</code> in this example):</p><div class="verbatim-wrap"><pre class="screen">Current Kubernetes cluster version: 1.15.2
Latest Kubernetes version: 1.16.2

Current Node version: 1.15.2

Component versions in master0
  - apiserver: 1.15.2 -&gt; 1.16.2
  - controller-manager: 1.15.2 -&gt; 1.16.2
  - scheduler: 1.15.2 -&gt; 1.16.2
  - etcd: 3.3.11 -&gt; 3.3.15
  - kubelet: 1.15.2 -&gt; 1.16.2
  - cri-o: 1.15.0 -&gt; 1.16.0</pre></div><p>It may happen that the Kubernetes version on the control plane is too outdated
for the update to progress. In this case, you would get output similar to the following:</p><div class="verbatim-wrap"><pre class="screen">Current Kubernetes cluster version: 1.15.0
Latest Kubernetes version: 1.15.0

Unable to plan node upgrade: at least one control plane does not tolerate the current cluster version</pre></div><div id="id-1.6.3.7.18" class="admonition tip normal"><img class="symbol" alt="Tip" title="Tip" src="static/images/icon-tip.png" /><h6>Tip</h6><p>The control plane consists of these components:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>apiserver</p></li><li class="listitem "><p>controller-manager</p></li><li class="listitem "><p>scheduler</p></li><li class="listitem "><p>etcd</p></li><li class="listitem "><p>kubelet</p></li><li class="listitem "><p>cri-o</p></li></ul></div></div></div><div class="sect2" id="_generating_an_overview_of_available_addon_updates"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.2.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Generating an Overview of Available Addon Updates</span> <a title="Permalink" class="permalink" href="_cluster_updates.html#_generating_an_overview_of_available_addon_updates">#</a></h3></div></div></div><div id="id-1.6.3.8.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>Due to changes to the way <code class="literal">skuba</code> handles addons some existing components might be shown as <code class="literal">new addon</code> in the status output.
This is expected and no cause for concern. For any upgrade afterwards the addon will be considered known and only show available upgrades.</p></div><div id="id-1.6.3.8.3" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>SUSE CaaS Platform 4.2.1 provides the update of Cilium from 1.5.3 to 1.6.6.
The important change in Cilium 1.6 is usage of Kubernetes CRDs instead of etcd.
<code class="literal">skuba</code> performs and automated migration of data from etcd to CRDs.
If that migration is not successful, <code class="literal">skuba</code> shows the following warning:</p><p><span class="emphasis"><em>"Could not migrate data from etcd to CRD. Addons upgrade will be continued without it,
which will result in temporary connection loss for currently existing pods and services."</em></span></p><p>That warning means that Cilium is going to regenerate all internal data on the first run after upgrade.
It can result in temporary connection loss for pods and services which might take few minutes.</p></div><p>Each Kubernetes cluster version comes with different addons base manifests.
To update your local addons cluster folder definition in-sync with
current Kubernetes cluster version, please run:</p><div class="verbatim-wrap"><pre class="screen">skuba addon refresh localconfig</pre></div><p>To get an overview of the addon updates available with validating the addon base and patches manifest before being applied to the current cluster, you can run:</p><div class="verbatim-wrap"><pre class="screen">skuba addon upgrade plan</pre></div><p>This will show you a list of updates (if available) for different addons
installed on the cluster:</p><div class="verbatim-wrap"><pre class="screen">Current Kubernetes cluster version: 1.17.4
Latest Kubernetes version: 1.17.4

Addon upgrades for 1.17.4:
  - cilium: 1.5.3 -&gt; 1.6.6
  - dex: 2.16.0 (manifest version from 5 to 6)
  - gangway: 3.1.0-rev4 (manifest version from 4 to 5)
  - metrics-server: 0.3.6 (new addon)</pre></div><p>If the cluster is already running the latest available
versions, the output should look like this:</p><div class="verbatim-wrap"><pre class="screen">Current Kubernetes cluster version: 1.17.4
Latest Kubernetes version: 1.17.4

Congratulations! Addons are already at the latest version available</pre></div><p>Before updating the nodes you must apply the addon upgrades to your management workstation.
Please run:</p><div class="verbatim-wrap"><pre class="screen">skuba addon upgrade apply</pre></div></div></div><div class="sect1" id="_updating_nodes"><div class="titlepage"><div><div><h2 class="title"><span class="number">4.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Updating Nodes</span> <a title="Permalink" class="permalink" href="_cluster_updates.html#_updating_nodes">#</a></h2></div></div></div><div id="id-1.6.4.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note</h6><p>It is recommended to use a load balancer with active health checks and pool management that
will take care of adding/removing nodes to/from the pool during this process.</p></div><p>Updates have to be applied separately to each node, starting with the control
plane all the way down to the worker nodes.</p><p>Note that the upgrade via <code class="literal">skuba node upgrade apply</code> will:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>Upgrade the containerized control plane.</p></li><li class="listitem "><p>Upgrade the rest of the Kubernetes system stack (<code class="literal">kubelet</code>, <code class="literal">cri-o</code>).</p></li><li class="listitem "><p>Restart services.</p></li></ul></div><p>During the upgrade to a newer version, the API server will be unavailable.</p><p>During the upgrade all the pods in the worker node will be restarted so it is
recommended to drain the pods if your application requires high availability.
In most cases, the restart is handled by <code class="literal">replicaSet</code>.</p><div class="sect2" id="_how_to_update_nodes"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.3.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">How To Update Nodes</span> <a title="Permalink" class="permalink" href="_cluster_updates.html#_how_to_update_nodes">#</a></h3></div></div></div><div class="orderedlist "><ol class="orderedlist" type="1"><li class="listitem "><p>Upgrade the master nodes:</p><div class="verbatim-wrap"><pre class="screen">skuba node upgrade apply --target &lt;MASTER_NODE_IP&gt; --user &lt;USER&gt; --sudo</pre></div></li><li class="listitem "><p>When all master nodes are upgraded, upgrade the worker nodes as well:</p><div class="verbatim-wrap"><pre class="screen">skuba node upgrade apply --target &lt;WORKER_NODE_IP&gt; --user &lt;USER&gt; --sudo</pre></div></li><li class="listitem "><p>Verify that your cluster nodes are upgraded by running:</p><div class="verbatim-wrap"><pre class="screen">skuba cluster upgrade plan</pre></div></li></ol></div><div id="id-1.6.4.8.3" class="admonition tip normal"><img class="symbol" alt="Tip" title="Tip" src="static/images/icon-tip.png" /><h6>Tip</h6><p>The upgrade via <code class="literal">skuba node upgrade apply</code> will:</p><div class="itemizedlist "><ul class="itemizedlist"><li class="listitem "><p>upgrade the containerized control plane.</p></li><li class="listitem "><p>upgrade the rest of the Kubernetes system stack (<code class="literal">kubelet</code>, <code class="literal">cri-o</code>).</p></li><li class="listitem "><p>temporarily drain/cordon the node before starting the whole process, and then undrain/uncordon the node after the upgrade has been successfully applied.</p></li><li class="listitem "><p>restart services.</p></li></ul></div></div></div><div class="sect2" id="_check_for_upgrades_to_new_version"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.3.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Check for Upgrades to New Version</span> <a title="Permalink" class="permalink" href="_cluster_updates.html#_check_for_upgrades_to_new_version">#</a></h3></div></div></div><p>Once you have upgraded all nodes, please run <code class="literal">skuba cluster upgrade plan</code> again.
This will show if any upgrades are available that required the versions you just installed.
If there are upgrades available please repeat the procedure until no more new upgrades are shown.</p></div></div><div class="sect1" id="base-os-updates"><div class="titlepage"><div><div><h2 class="title"><span class="number">4.4 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Base OS Updates</span> <a title="Permalink" class="permalink" href="_cluster_updates.html#base-os-updates">#</a></h2></div></div></div><p>Base operating system updates are handled by <code class="literal">skuba-update</code>, which works together
with the <code class="literal">kured</code> reboot daemon.</p><div class="sect2" id="disabling-automatic-updates"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.4.1 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Disabling Automatic Updates</span> <a title="Permalink" class="permalink" href="_cluster_updates.html#disabling-automatic-updates">#</a></h3></div></div></div><p>Nodes added to a cluster have the service <code class="literal">skuba-update.timer</code>, which is responsible for running automatic updates, activated by default.</p><p>This service calls the <code class="literal">skuba-update</code> utility and it can be configured with the <code class="literal">/etc/sysconfig/skuba-update</code> file.</p><div id="id-1.6.5.3.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.png" /><h6>Note: How skuba-update non-interactive mode works</h6><p><code class="literal">skuba-update</code> uses the flags <code class="literal">--non-interactive</code> and <code class="literal">--non-interactive-include-reboot-patches</code>. The <code class="literal">--non-interactive</code> flag causes zypper to use default answers to questions rather than prompting a user for answers.  In non-interactive mode, the <code class="literal">--non-interactive-include-reboot-patches</code> flag causes patches with the <code class="literal">rebootSuggested-flag</code> to not be skipped. Zypper does not perform the reboot directly. Instead, <code class="literal">kured</code> will be used to safely schedule reboots as needed.</p></div><p>To disable the automatic updates on a node, simply <code class="literal">ssh</code> to it and then configure the skuba-update service by editing the <code class="literal">/etc/sysconfig/skuba-update</code> file with the following runtime options:</p><div class="verbatim-wrap"><pre class="screen">## Path           : System/Management
## Description    : Extra switches for skuba-update
## Type           : string
## Default        : ""
## ServiceRestart : skuba-update
#
SKUBA_UPDATE_OPTIONS="--annotate-only"</pre></div><div id="id-1.6.5.3.7" class="admonition tip normal"><img class="symbol" alt="Tip" title="Tip" src="static/images/icon-tip.png" /><h6>Tip</h6><p>It is not required to reload or restart <code class="literal">skuba-update.timer</code>.</p></div><p>The <code class="literal">--annotate-only</code> flag makes the <code class="literal">skuba-update</code> utility only check if updates are available and annotate the node accordingly.
When this flag is activated no updates are installed at all.</p><p>When OS updates are disabled, then you will have to manage OS updates manually. In order to do so, you will have to call <code class="literal">skuba-update</code> manually on each node.</p><div id="id-1.6.5.3.10" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.png" /><h6>Warning</h6><p>Do not use <code class="literal">zypper up/zypper patch</code> commands as these do not manage the Kubernetes annotations used by <code class="literal">kured</code>.
If you perform a manual update using these commands you might render your cluster unusable.</p></div><p>After that, rebooting the node will depend on whether you have also disabled reboots or not. If you have disabled reboots for this node, then you will have to follow the instructions as given in <a class="xref" href="_cluster_updates.html#_completely_disabling_reboots" title="4.4.2. Completely Disabling Reboots">Section 4.4.2, “Completely Disabling Reboots”</a>. Otherwise, you will have to wait until <code class="literal">kured</code> performs the reboot of the node</p></div><div class="sect2" id="_completely_disabling_reboots"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.4.2 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Completely Disabling Reboots</span> <a title="Permalink" class="permalink" href="_cluster_updates.html#_completely_disabling_reboots">#</a></h3></div></div></div><p>If you would like to take care of reboots manually, either as a temporary measure or permanently, you can disable them by creating a lock:</p><div class="verbatim-wrap"><pre class="screen">kubectl -n kube-system annotate ds kured weave.works/kured-node-lock='{"nodeID":"manual"}'</pre></div><p>This command modifies an annotation (<code class="literal">annotate</code>) on the daemonset (<code class="literal">ds</code>) named <code class="literal">kured</code>.</p><p>When automatic reboots are disabled, you will have to manage reboots yourself.
In order to do this, you will have to follow some steps whenever you want to issue a reboot marker for a node.
First of all, you will have to <code class="literal">cordon</code> and <a class="link" href="https://v1-18.docs.kubernetes.io/docs/tasks/administer-cluster/safely-drain-node/" target="_blank"><code class="literal">drain</code></a> the node:</p><div class="verbatim-wrap"><pre class="screen">kubectl cordon &lt;NODE_ID&gt;
kubectl drain --force=true \
  --ignore-daemonsets=true \ <span id="CO1-1"></span><span class="callout">1</span>
  --delete-local-data=false \ <span id="CO1-2"></span><span class="callout">2</span>
  --grace-period 600 \ <span id="CO1-3"></span><span class="callout">3</span>
  --timeout=900s \ <span id="CO1-4"></span><span class="callout">4</span>
  &lt;NODE_ID&gt;</pre></div><div class="calloutlist "><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO1-1"><span class="callout">1</span></a> </p></td><td valign="top" align="left"><p>Core components like <code class="literal">kured</code> and <code class="literal">cilium</code> are running as <code class="literal">DaemonSet</code> and draining those pods will fail if this is not set to <code class="literal">true</code>.</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO1-2"><span class="callout">2</span></a> </p></td><td valign="top" align="left"><p>Continues even if there are pods using <code class="literal">emptyDir</code> (local data that will be deleted when the node is drained; e.g: <code class="literal">metrics-server</code>).</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO1-3"><span class="callout">3</span></a> </p></td><td valign="top" align="left"><p>Running applications will be notified of termination and given 10 minutes (<code class="literal">600</code> seconds) to safely store data.</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO1-4"><span class="callout">4</span></a> </p></td><td valign="top" align="left"><p>Draining of the node will fail after 15 minutes (<code class="literal">900</code> seconds) have elapsed without success.</p></td></tr></table></div><div id="id-1.6.5.4.8" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.png" /><h6>Important</h6><p>Depending on your deployed applications, you must adjust the values for <code class="literal">--grace-period</code> and <code class="literal">--timeout</code> to grant the applications enough time to safely shut down without losing data.
The values here are meant to represent a conservative default for an application like SUSE Cloud Application Platform.</p><p>If you do not set these values, applications might never finish and draining of the pod will hang indefinitely.</p></div><p>Only then you will be able to manually <code class="literal">reboot</code> the node safely.</p><p>Once the node is back, remember to <code class="literal">uncordon</code> it so it is scheduleable again:</p><div class="verbatim-wrap"><pre class="screen">kubectl uncordon &lt;NODE_ID&gt;</pre></div><p>Perform the above steps first on control plane nodes, and afterwards on worker nodes.</p><div id="id-1.6.5.4.13" class="admonition tip normal"><img class="symbol" alt="Tip" title="Tip" src="static/images/icon-tip.png" /><h6>Tip</h6><p>If the node that should be rebooted does not contain any workload you can skip the above steps and simply reboot the node.</p></div></div><div class="sect2" id="_manual_unlock"><div class="titlepage"><div><div><h3 class="title"><span class="number">4.4.3 </span><span xmlns:dm="urn:x-suse:ns:docmanager" class="name">Manual Unlock</span> <a title="Permalink" class="permalink" href="_cluster_updates.html#_manual_unlock">#</a></h3></div></div></div><p>In exceptional circumstances, such as a node experiencing a permanent failure whilst rebooting, manual intervention may be required to remove the cluster lock:</p><div class="verbatim-wrap"><pre class="screen">kubectl -n kube-system annotate ds kured weave.works/kured-node-lock-</pre></div><p>This command modifies an annotation (<code class="literal">annotate</code>) on the daemonset (<code class="literal">ds</code>) named <code class="literal">kured</code>.
It explicitly performs an "unset" (<code class="literal">-</code>) for the value for the annotation named <code class="literal">weave.works/kured-node-lock</code>.</p></div></div></div></div><div class="page-bottom"><div id="_bottom-navigation"><a class="nav-link" href="_upgrading_suse_caas_platform.html"><span class="next-icon">→</span><span class="nav-label"><span class="number">Chapter 5 </span>Upgrading SUSE CaaS Platform</span></a><a class="nav-link" href="_software_management.html"><span class="prev-icon">←</span><span class="nav-label"><span class="number">Chapter 3 </span>Software Management</span></a></div><div class="_share-print"><div class="online-contents share"><strong>Share this page: </strong><span class="share-buttons"><span class="_share-fb bottom-button">Facebook</span><span class="spacer"> • </span><span class="_share-in bottom-button">LinkedIn</span><span class="spacer"> • </span><span class="_share-tw bottom-button">Twitter</span><span class="spacer"> • </span><span class="_share-mail bottom-button">E-Mail</span></span></div><div class="print"><span class="_print-button bottom-button">Print this page</span></div><div class="clearme"></div></div></div></div><div id="_inward"></div></div><div id="_footer-wrap"><div id="_footer"><p>©
        2020 
        SUSE</p><ul><li><a href="https://jobs.suse.com/" target="_top">Careers</a></li><li><a href="https://www.suse.com/company/legal/" target="_top">Legal</a></li><li><a href="https://www.suse.com/company/about/" target="_top">About</a></li><li><a href="https://www.suse.com/contact/" target="_top">Contact Us</a></li></ul></div></div></body></html>